{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect `data/baby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting dataset: baby ---\n",
      "Columns: ['userID', 'itemID', 'rating', 'timestamp', 'x_label']\n",
      "        userID  itemID  x_label\n",
      "160787   19444    7022        0\n",
      "160788   19444    6959        0\n",
      "160789   19444    7005        0\n",
      "160790   19444    7023        1\n",
      "160791   19444    6994        2\n",
      "#users:  19445, max:  19444\n",
      "#items:   7050, max:   7049\n",
      "#filtered interactions: 160792\n",
      "\n",
      "Shape of image_feat: (7050, 4096)\n",
      "Shape of text_feat : (7050, 384)\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def inspect_dataset(name, data_path, config_path):\n",
    "    with open(config_path, 'r', encoding='utf-8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # Load inter_file\n",
    "    inter_file_path = f'{data_path}/{config[\"inter_file_name\"]}'\n",
    "    image_file_path = f'{data_path}/{config[\"vision_feature_file\"]}'\n",
    "    text_file_path = f'{data_path}/{config[\"text_feature_file\"]}'\n",
    "\n",
    "    inter_df = pd.read_csv(inter_file_path, sep='\\t')\n",
    "    image_feat = np.load(image_file_path, allow_pickle=True)\n",
    "    text_feat = np.load(text_file_path, allow_pickle=True)\n",
    "    \n",
    "    # Inspect the dataframe\n",
    "    print(f'--- Inspecting dataset: {name} ---')\n",
    "    print(f'Columns: {inter_df.columns.tolist()}')\n",
    "    print(inter_df[['userID', 'itemID', 'x_label']].tail())\n",
    "    print(f'#users: {len(inter_df[\"userID\"].unique()):6}, max: {inter_df[\"userID\"].max():6}')\n",
    "    print(f'#items: {len(inter_df[\"itemID\"].unique()):6}, max: {inter_df[\"itemID\"].max():6}')\n",
    "    print(f'#filtered interactions: {len(inter_df)}\\n')\n",
    "\n",
    "    print(f'Shape of image_feat: {image_feat.shape}')\n",
    "    print(f'Shape of text_feat : {text_feat.shape}')\n",
    "    print('-----------------------------------\\n')\n",
    "\n",
    "dataset_name = 'baby'\n",
    "data_path = f'data/{dataset_name}'\n",
    "config_path = f'src/configs/dataset/{dataset_name}.yaml'\n",
    "inspect_dataset(dataset_name, data_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting dataset: Music4All ---\n",
      "Columns: ['userID', 'itemID', 'x_label']\n",
      "         userID  itemID  x_label\n",
      "5058229   14124   14553        2\n",
      "5058230   14124    7313        2\n",
      "5058231   14124   62596        2\n",
      "5058232   14124   63684        2\n",
      "5058233   14124   14553        2\n",
      "#users:  14125, max:  14124\n",
      "#items:  80735, max:  80734\n",
      "#filtered interactions: 5058234\n",
      "\n",
      "Shape of image_feat: (80735, 1024)\n",
      "Shape of text_feat : (80735, 384)\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Music4All'\n",
    "# Now using junction - simpler path!\n",
    "data_path = f'data/{dataset_name}'  # Junction points to Dragon-for-Music/data/Music4All\n",
    "config_path = f'src/configs/dataset/{dataset_name}.yaml'\n",
    "inspect_dataset(dataset_name, data_path, config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content below was copied from `Dragon-for-Music`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All features - Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         userID  itemID  x_label\n",
      "5058229   14126   19690        2\n",
      "5058230   14126    9878        2\n",
      "5058231   14126   84677        2\n",
      "5058232   14126   86170        2\n",
      "5058233   14126   19690        2\n",
      "#users: 14125, max: 14126\n",
      "#items: 80735, max: 109268\n",
      "#filtered interactions: 5058234\n",
      "Shape of text_feature : (109269, 384)\n",
      "Shape of audio_feature: (109269, 1024)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "data_path = 'data/Music4All'\n",
    "config_path = f'configs/dataset/Music4All.yaml'\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Load interaction file and features\n",
    "inter_file_path = os.path.join(data_path, config['inter_file_name'])\n",
    "text_feature_path = os.path.join(data_path, config['text_feature_file'])            # text_feat.npy -> clean_\n",
    "audio_feature_path = os.path.join(data_path, config['vision_feature_file'])         # audio_feat_mert.npy -> clean_\n",
    "\n",
    "inter_df = pd.read_csv(inter_file_path, sep='\\t')\n",
    "text_feature = np.load(text_feature_path)\n",
    "audio_feature = np.load(audio_feature_path)\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(inter_df[['userID', 'itemID', 'x_label']].tail())\n",
    "print(f'#users: {inter_df[\"userID\"].nunique()}, max: {inter_df[\"userID\"].max()}')\n",
    "print(f'#items: {inter_df[\"itemID\"].nunique()}, max: {inter_df[\"itemID\"].max()}')\n",
    "print(f'#filtered interactions: {len(inter_df)}')\n",
    "\n",
    "print(f'Shape of text_feature : {text_feature.shape}')\n",
    "print(f'Shape of audio_feature: {audio_feature.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only items with interactions\n",
    "inter_df['itemID'], unique_item_list = pd.factorize(inter_df['itemID'], sort=True)\n",
    "unique_item_list = unique_item_list.tolist()\n",
    "\n",
    "clean_text_feature = text_feature[unique_item_list]\n",
    "clean_audio_feature = audio_feature[unique_item_list]\n",
    "\n",
    "np.save(f\"{data_path}/clean_text_feat.npy\", clean_text_feature)\n",
    "np.save(f\"{data_path}/clean_audio_feat.npy\", clean_audio_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure #users = max+1 (no skipping ids)\n",
    "inter_df['userID'], uniques = pd.factorize(inter_df['userID'], sort=True)\n",
    "print(inter_df.tail())\n",
    "print(f'#users: {inter_df[\"userID\"].nunique()}, max: {inter_df[\"userID\"].max()}')\n",
    "print(f'#items: {inter_df[\"itemID\"].nunique()}, max: {inter_df[\"itemID\"].max()}')\n",
    "print(f'#filtered interactions: {len(inter_df)}')\n",
    "\n",
    "inter_df.to_csv(f\"{data_path}/clean_filtered_interactions.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All: Audio features\n",
    "\n",
    "See `tools.m4a_data_prep.prep_audio_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All: Text features\n",
    "Activate the `sbert` conda env for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tools.m4a_data_prep import load_json_from_gcs, prep_text_features\n",
    "\n",
    "music4all_dir = 'gs://music4all/Music4All/'\n",
    "attr_path = os.path.join(music4all_dir, 'processed/attributes.json')\n",
    "val_path = os.path.join(music4all_dir, 'processed/attribute_values.json')\n",
    "\n",
    "attributes = load_json_from_gcs(attr_path)\n",
    "val = load_json_from_gcs(val_path)\n",
    "\n",
    "# text_feat = prep_text_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val=dict_keys(['artist', 'album_name', 'lang', 'release', 'key', 'mode', 'genre', 'tag'])\n",
      "Genres: count=  853; ['8-bit', 'a cappella', 'abstract', 'abstract hip hop', 'accordion', 'acid house', 'acid jazz', 'acid techno', 'acousmatic', 'acoustic blues', 'acoustic pop', 'adoracao', 'adventista', 'afrikaans', 'afro-funk', 'afrobeat', 'afropop', 'aggrotech', 'albanian pop', 'album rock', 'alternative country', 'alternative dance', 'alternative hip hop', 'alternative metal', 'alternative metalcore', 'alternative pop', 'alternative pop rock', 'alternative rock', 'ambient', 'ambient folk', 'ambient industrial', 'ambient techno', 'anadolu rock', 'anarcho-punk', 'anime', 'anthem', 'anti-folk', 'arabesk', 'armenian folk', 'armenian pop', 'art pop', 'art rock', 'asmr', 'atmosphere', 'atmospheric black metal', 'atmospheric doom', 'atmospheric sludge', 'australian rock', 'austropop', 'avant-garde']\n",
      "Tags  : count=19541; [' ', ' ambient', ' blues rock', ' classic rock', ' dance', ' dark ambient', ' deathcore', ' electronic', ' electronica', ' female vocalist', ' female vocalists', ' hip hop', ' house', ' male vocalists', ' oldies', ' piano', ' pop', ' pop rock', ' post-punk', ' post-rock', ' progressive metal', ' rock', ' rock and roll', ' synth pop', '#alternative', '#cagetheelephant', '#dayumintro', '#dope', '#newpshyhedelic', '#rockalternativo', '#yaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaas', '&lt;&gt;&lt;', '&lt;3', '&lt;33', \"'90s\", '+30mg', '-', '- - rainy day - -', '- - woods - -', '---21fh', '---28fh', '--1', '--4', '--5', '-10', '-15t', '-2', '-25t', '-3', '-30t']\n"
     ]
    }
   ],
   "source": [
    "print(f'val={val.keys()}')\n",
    "print(f'Genres: count={len(val[\"genre\"]):5}; {val[\"genre\"][:50]}')\n",
    "print(f'Tags  : count={len(val[\"tag\"]):5}; {val[\"tag\"][:50]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'song_id': '2Z3mv11Pg2Xdj3Fp', 'artist': 14998, 'album_name': 12017, 'lang': 11, 'release': 85, 'key': 7, 'mode': 1, 'genre': [338, 480, 337, 684], 'tag': [7029, 10381, 370, 7028, 7024, 14907]}\n"
     ]
    }
   ],
   "source": [
    "print(attributes['items'][4589])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ty Segall\n",
      "Freedom's Goblin\n",
      "2018\n",
      "garage rock\n",
      "lo-fi\n",
      "garage punk\n",
      "rock\n",
      "garage rock\n",
      "lo-fi\n",
      "2018\n",
      "garage punk\n",
      "garage\n",
      "rock\n"
     ]
    }
   ],
   "source": [
    "print(val['artist'][14998])\n",
    "print(val['album_name'][12017])\n",
    "print(val['release'][85])\n",
    "for i in [338, 480, 337, 684]:\n",
    "    print(val['genre'][i])\n",
    "for i in [7029, 10381, 370, 7028, 7024, 14907]:\n",
    "    print(val['tag'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All: Interaction data\n",
    "\n",
    "**`interaction.json`**\n",
    "```\n",
    "{\n",
    "  0: [12233, 23344, ...],\n",
    "  1: [],\n",
    "  ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userID  itemID  x_label\n",
      "5058229  14126   19690        2\n",
      "5058230  14126    9878        2\n",
      "5058231  14126   84677        2\n",
      "5058232  14126   86170        2\n",
      "5058233  14126   19690        2\n",
      "#users: 14125\n",
      "#items: 80735\n",
      "#filtered interactions: 5058234\n",
      "        userID  itemID  x_label\n",
      "5058229  14126   19690        2\n",
      "5058230  14126    9878        2\n",
      "5058231  14126   84677        2\n",
      "5058232  14126   86170        2\n",
      "5058233  14126   19690        2\n",
      "#users: 14125\n",
      "#items: 80735\n",
      "#filtered interactions: 5058234\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tools.m4a_data_prep import prep_interaction_data\n",
    "\n",
    "music4all_dir = 'gs://music4all/Music4All/'\n",
    "inter_path = os.path.join(music4all_dir, 'processed/interactions.json')\n",
    "attr_path = os.path.join(music4all_dir, 'processed/attributes.json')\n",
    "\n",
    "df = prep_interaction_data(inter_path, attr_path)\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(df.tail())\n",
    "print(f'#users: {len(df[\"userID\"].unique())}')\n",
    "print(f'#items: {len(df[\"itemID\"].unique())}')\n",
    "print(f'#filtered interactions: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if `interactions.json` preserves order from `listening_history.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            user              song         timestamp\n",
      "0  user_007XIjOr  DaTQ53TUmfP93FSr  2019-02-20 12:28\n",
      "1  user_007XIjOr  dGeyvi5WCOjDU7da  2019-02-20 12:35\n",
      "2  user_007XIjOr  qUm54NYOjeFhmKYx  2019-02-20 12:48\n",
      "3  user_007XIjOr  FtnuMT1DlevSR2n5  2019-02-20 12:52\n",
      "4  user_007XIjOr  LHETTZcSZLeaVOGh  2019-02-20 13:09\n"
     ]
    }
   ],
   "source": [
    "from gcs_utils import read_tsv_from_gcs\n",
    "\n",
    "hist_path = os.path.join(music4all_dir, 'listening_history.csv')\n",
    "df_listening_history = read_tsv_from_gcs(hist_path)\n",
    "\n",
    "print(df_listening_history.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking order preservation for 20 random users...\n",
      "\n",
      "User user_z4gXXNYv (encoded 13924): MISMATCH\n",
      "  First mismatch at index 203:\n",
      "    CSV context : [36963, 33688, 45464, 60178, 18463, 43264, 18463, 105599, 36364, 87603, 23975]\n",
      "    JSON context: [36963, 33688, 45464, 60178, 18463, 18463, 43264, 105599, 36364, 87603, 23975]\n",
      "  CSV length=386, JSON length=386\n",
      "\n",
      "User user_evGC0u2F (encoded 9315): MISMATCH\n",
      "  First mismatch at index 94:\n",
      "    CSV context : [4478, 14231, 47004, 29618, 35792, 5440, 53766, 79581, 102157, 6173, 102157]\n",
      "    JSON context: [4478, 14231, 47004, 29618, 35792, 53766, 5440, 79581, 102157, 6173, 102157]\n",
      "  CSV length=325, JSON length=325\n",
      "\n",
      "User user_Go9F9fEh (encoded 3945): MISMATCH\n",
      "  First mismatch at index 80:\n",
      "    CSV context : [104867, 24814, 80232, 56284, 47671, 5516, 74695, 56284, 1920, 52264, 104867]\n",
      "    JSON context: [104867, 24814, 80232, 56284, 47671, 74695, 5516, 56284, 1920, 52264, 104867]\n",
      "  CSV length=356, JSON length=356\n",
      "\n",
      "User user_amW83YPG (encoded 8396): OK\n",
      "User user_UmyMyUZG (encoded 7053): MISMATCH\n",
      "  First mismatch at index 43:\n",
      "    CSV context : [36618, 93780, 79052, 79950, 79774, 79774, 84876, 27379, 26799, 107806, 29111]\n",
      "    JSON context: [36618, 93780, 79052, 79950, 79774, 84876, 79774, 27379, 26799, 107806, 29111]\n",
      "  CSV length=238, JSON length=238\n",
      "\n",
      "User user_Nzttg4pb (encoded 5552): MISMATCH\n",
      "  First mismatch at index 243:\n",
      "    CSV context : [14729, 14729, 6904, 15982, 15982, 14729, 11571, 11571, 15982, 104640, 104640]\n",
      "    JSON context: [14729, 14729, 6904, 15982, 15982, 11571, 11571, 14729, 15982, 104640, 104640]\n",
      "  CSV length=386, JSON length=386\n",
      "\n",
      "User user_jwplUdJx (encoded 10505): OK\n",
      "User user_Zwy5adJh (encoded 8231): MISMATCH\n",
      "  First mismatch at index 74:\n",
      "    CSV context : [107586, 59585, 67064, 46999, 34878, 15366, 80719, 9611, 16339, 22444, 68387]\n",
      "    JSON context: [107586, 59585, 67064, 46999, 34878, 80719, 15366, 9611, 16339, 22444, 68387]\n",
      "  CSV length=310, JSON length=310\n",
      "\n",
      "User user_ztWGGYqQ (encoded 14097): MISMATCH\n",
      "  First mismatch at index 65:\n",
      "    CSV context : [18768, 44895, 52314, 18768, 30646, 77694, 30646, 66512, 36052, 12750, 1992]\n",
      "    JSON context: [18768, 44895, 52314, 18768, 30646, 30646, 77694, 66512, 36052, 12750, 1992]\n",
      "  CSV length=307, JSON length=307\n",
      "\n",
      "User user_OcITazbb (encoded 5675): OK\n",
      "User user_GOAyb1zl (encoded 3841): MISMATCH\n",
      "  First mismatch at index 48:\n",
      "    CSV context : [70592, 71206, 106973, 86375, 924, 87939, 107080, 71206, 89429, 93578, 27902]\n",
      "    JSON context: [70592, 71206, 106973, 86375, 924, 107080, 87939, 71206, 89429, 93578, 27902]\n",
      "  CSV length=377, JSON length=377\n",
      "\n",
      "User user_F8i6YbND (encoded 3534): MISMATCH\n",
      "  First mismatch at index 15:\n",
      "    CSV context : [32246, 43072, 78733, 60757, 73502, 25917, 78733, 43072, 78733, 32246, 106934]\n",
      "    JSON context: [32246, 43072, 78733, 60757, 73502, 43072, 78733, 25917, 78733, 32246, 106934]\n",
      "  CSV length=286, JSON length=286\n",
      "\n",
      "User user_4iW03QJr (encoded 1133): MISMATCH\n",
      "  First mismatch at index 118:\n",
      "    CSV context : [36421, 79814, 45965, 9855, 101756, 104867, 101756, 52314, 58817, 95248, 22011]\n",
      "    JSON context: [36421, 79814, 45965, 9855, 101756, 101756, 104867, 52314, 58817, 95248, 22011]\n",
      "  CSV length=405, JSON length=405\n",
      "\n",
      "User user_jgjQGyUN (encoded 10445): MISMATCH\n",
      "  First mismatch at index 133:\n",
      "    CSV context : [45984, 7606, 70135, 70135, 29945, 61409, 54338, 27296, 70135, 13055, 70640]\n",
      "    JSON context: [45984, 7606, 70135, 70135, 29945, 54338, 61409, 27296, 70135, 13055, 70640]\n",
      "  CSV length=352, JSON length=352\n",
      "\n",
      "User user_CMIS6jVV (encoded 2862): MISMATCH\n",
      "  First mismatch at index 242:\n",
      "    CSV context : [15982, 6904, 11571, 6362, 47101, 47101, 46760, 16774, 107255, 61250, 75827]\n",
      "    JSON context: [15982, 6904, 11571, 6362, 47101, 46760, 47101, 16774, 107255, 61250, 75827]\n",
      "  CSV length=397, JSON length=397\n",
      "\n",
      "User user_OkojHRw7 (encoded 5710): MISMATCH\n",
      "  First mismatch at index 84:\n",
      "    CSV context : [4014, 40578, 71396, 6047, 7772, 65586, 22728, 37373, 17277, 9950, 98488]\n",
      "    JSON context: [4014, 40578, 71396, 6047, 7772, 22728, 65586, 37373, 17277, 9950, 98488]\n",
      "  CSV length=442, JSON length=442\n",
      "\n",
      "User user_jZb5w2Gi (encoded 10411): OK\n",
      "User user_99ag1aCc (encoded 2158): MISMATCH\n",
      "  First mismatch at index 57:\n",
      "    CSV context : [43793, 85901, 107051, 83374, 84105, 37894, 13443, 87159, 106632, 41372, 8689]\n",
      "    JSON context: [43793, 85901, 107051, 83374, 84105, 13443, 37894, 87159, 106632, 41372, 8689]\n",
      "  CSV length=466, JSON length=466\n",
      "\n",
      "User user_3pVh5ryK (encoded 908): OK\n",
      "User user_iBJHb2Lj (encoded 10080): MISMATCH\n",
      "  First mismatch at index 375:\n",
      "    CSV context : [14889, 14889, 106772, 82106, 40610, 101174, 40610, 101174, 49051, 57133, 80079]\n",
      "    JSON context: [14889, 14889, 106772, 82106, 40610, 40610, 101174, 101174, 49051, 57133, 80079]\n",
      "  CSV length=394, JSON length=394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from tools.m4a_data_prep import load_json_from_gcs\n",
    "\n",
    "inter_path = 'gs://music4all/Music4All/processed/interactions.json'\n",
    "interactions = load_json_from_gcs(inter_path)\n",
    "\n",
    "def first_mismatch_with_context(list1, list2, window=10):\n",
    "    \"\"\"Return index, values, and context slices around the first mismatch.\"\"\"\n",
    "    for i, (a, b) in enumerate(zip(list1, list2)):\n",
    "        if a != b:\n",
    "            half = window // 2\n",
    "            start = max(0, i - half)\n",
    "            end = i + half + 1\n",
    "            return i, list1[start:end], list2[start:end]\n",
    "    if len(list1) != len(list2):\n",
    "        i = min(len(list1), len(list2))\n",
    "        half = window // 2\n",
    "        start = max(0, i - half)\n",
    "        end = i + half + 1\n",
    "        return i, list1[start:end], list2[start:end]\n",
    "    return None\n",
    "\n",
    "df = df_listening_history.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "# df = df_listening_history\n",
    "\n",
    "# Build lookup dicts for encoding\n",
    "user_to_idx = {u[\"user_id\"]: idx for idx, u in enumerate(attributes[\"users\"])}\n",
    "item_to_idx = {i[\"song_id\"]: idx for idx, i in enumerate(attributes[\"items\"])}\n",
    "\n",
    "# === Randomly sample 20 users ===\n",
    "all_users = df[\"user\"].unique().tolist()\n",
    "sample_users = random.sample(all_users, min(20, len(all_users)))\n",
    "\n",
    "print(\"Checking order preservation for 20 random users...\\n\")\n",
    "\n",
    "for user_id in sample_users:\n",
    "    user_idx = user_to_idx[user_id]\n",
    "\n",
    "    # from CSV (chronological order)\n",
    "    user_df = df[df[\"user\"] == user_id]\n",
    "    csv_songs = [item_to_idx[song] for song in user_df[\"song\"].tolist()]\n",
    "\n",
    "    # from JSON\n",
    "    json_songs = interactions.get(str(user_idx), [])\n",
    "\n",
    "    # compare\n",
    "    match = csv_songs == json_songs\n",
    "    print(f\"User {user_id} (encoded {user_idx}): \"\n",
    "        f\"{'OK' if match else 'MISMATCH'}\")\n",
    "\n",
    "    if not match:\n",
    "        mm = first_mismatch_with_context(csv_songs, json_songs, window=10)\n",
    "        if mm:\n",
    "            idx, csv_context, json_context = mm\n",
    "            print(f\"  First mismatch at index {idx}:\")\n",
    "            print(f\"    CSV context : {csv_context}\")\n",
    "            print(f\"    JSON context: {json_context}\")\n",
    "        print(f\"  CSV length={len(csv_songs)}, JSON length={len(json_songs)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user              song         timestamp\n",
      "773053  user_99ag1aCc  lrL4RAKX6f8Tz2h9  2019-01-23 13:59\n",
      "773054  user_99ag1aCc  gV9zey0BURekfwUz  2019-01-23 15:32\n",
      "773055  user_99ag1aCc  TjyPWv8mZY4HyiHG  2019-01-23 15:36\n",
      "773056  user_99ag1aCc  mqcCD4gTbcbp524p  2019-01-23 15:40\n",
      "773057  user_99ag1aCc  QKtqOEayujT7uiN8  2019-01-23 15:46\n",
      "773058  user_99ag1aCc  hiZOnY63Q67hWHMU  2019-01-23 18:27\n",
      "773059  user_99ag1aCc  SF0M6cQhMuaeirB5  2019-01-23 18:31\n",
      "773060  user_99ag1aCc  zDJheSwyuy4euMpX  2019-01-23 18:34\n",
      "773061  user_99ag1aCc  bgaW0PAE9g3ndI3H  2019-01-23 20:17\n",
      "773062  user_99ag1aCc  rfaYNZCE9bm2ERQI  2019-01-23 20:25\n",
      "773063  user_99ag1aCc  X90FM1k6kIL08QcO  2019-01-23 20:29\n",
      "773064  user_99ag1aCc  pzDReyjgfMr7mNTX  2019-01-23 20:33\n",
      "773065  user_99ag1aCc  82gbxU2ARroqVp1r  2019-01-24 14:42\n",
      "773066  user_99ag1aCc  BdpE84qRXtc9deX6  2019-01-24 14:47\n",
      "773067  user_99ag1aCc  rwM0ld0uwxjMK9Fh  2019-01-24 14:51\n",
      "773068  user_99ag1aCc  WHPR9OrFBOToYWXJ  2019-01-24 14:56\n",
      "773069  user_99ag1aCc  yqNY16s5yT0amiRZ  2019-01-24 15:01\n",
      "773070  user_99ag1aCc  kYYEw62LOX3v5RSg  2019-01-24 17:36\n",
      "773071  user_99ag1aCc  XT6awgFXZtMr2hbP  2019-01-24 17:41\n",
      "773072  user_99ag1aCc  lKHB4iC9HPTZLc7i  2019-01-24 17:45\n",
      "773073  user_99ag1aCc  R5gBzwNyzql9kzs3  2019-01-24 17:50\n",
      "773074  user_99ag1aCc  UamCmdVPgN6B4DMa  2019-01-24 17:54\n",
      "773075  user_99ag1aCc  n7xy1GPYNyMYgusl  2019-01-24 18:00\n",
      "773076  user_99ag1aCc  RPmWvNfWjSNfwcay  2019-01-25 14:35\n",
      "773077  user_99ag1aCc  yfm7RER1PWTqgjIp  2019-01-25 14:42\n",
      "773078  user_99ag1aCc  IiKMWlJ4N1MvBpHc  2019-01-25 14:45\n",
      "773079  user_99ag1aCc  rrsXRmaMir5yOrZf  2019-01-25 14:50\n",
      "773080  user_99ag1aCc  EmPJO7fTwQlTDjGG  2019-01-25 14:54\n",
      "773081  user_99ag1aCc  OvGwrp7cisRK2xw8  2019-01-25 15:01\n",
      "773082  user_99ag1aCc  CTB8ewr815LhFQHe  2019-01-25 15:04\n",
      "773083  user_99ag1aCc  kCJHgbVuvdOLX9fK  2019-01-25 15:07\n",
      "773084  user_99ag1aCc  KVNTAVj6n3JYvD62  2019-01-25 17:58\n",
      "773085  user_99ag1aCc  waWpImm1As7LxqrC  2019-01-25 18:02\n",
      "773086  user_99ag1aCc  CsYEhTtAWbA4m1A9  2019-01-25 18:07\n",
      "773087  user_99ag1aCc  5cPojQi6lGT6v6vY  2019-01-25 18:10\n",
      "773088  user_99ag1aCc  QHpSMv1WsSt3wr48  2019-01-25 18:15\n",
      "773089  user_99ag1aCc  yMBMsrb9prNZKdVI  2019-01-25 18:20\n",
      "773090  user_99ag1aCc  iUcyvVWtHhpX0kyd  2019-01-25 18:24\n",
      "773091  user_99ag1aCc  Y4fqXBKf1ohU1RVD  2019-01-25 18:28\n",
      "773092  user_99ag1aCc  BP9cUEbDxszul8jF  2019-01-25 18:33\n",
      "773093  user_99ag1aCc  pLKeEmwpCncgcbZG  2019-01-25 18:37\n",
      "773094  user_99ag1aCc  JduzBnlSWG90zUbw  2019-01-25 19:55\n",
      "773095  user_99ag1aCc  gV9zey0BURekfwUz  2019-01-25 19:55\n",
      "773096  user_99ag1aCc  JduzBnlSWG90zUbw  2019-01-25 19:55\n",
      "773097  user_99ag1aCc  TjyPWv8mZY4HyiHG  2019-01-25 20:00\n",
      "773098  user_99ag1aCc  mqcCD4gTbcbp524p  2019-01-25 20:04\n",
      "773099  user_99ag1aCc  QKtqOEayujT7uiN8  2019-01-25 20:10\n",
      "773100  user_99ag1aCc  XA9SwTx1F83oAjVI  2019-01-26 16:45\n",
      "773101  user_99ag1aCc  gV9zey0BURekfwUz  2019-01-27 15:23\n",
      "773102  user_99ag1aCc  TjyPWv8mZY4HyiHG  2019-01-27 15:27\n",
      "773103  user_99ag1aCc  YGhy20IyV1owojFa  2019-01-27 15:39\n",
      "773104  user_99ag1aCc  32m5suoC94ytD8Ed  2019-01-28 17:35\n",
      "773105  user_99ag1aCc  OoS59bfFx3nnkAJD  2019-01-28 17:38\n",
      "773106  user_99ag1aCc  mmLy5yZjUvxea3jy  2019-01-28 18:41\n",
      "773107  user_99ag1aCc  yj5hUpgxoy0S4F1m  2019-01-29 15:21\n",
      "773108  user_99ag1aCc  lJKIbZNzpS6IsNgh  2019-01-29 15:30\n",
      "773109  user_99ag1aCc  lj6ySCyFmRM53Kg1  2019-01-29 15:34\n",
      "773110  user_99ag1aCc  7dKoROBrFjEeDkwD  2019-01-29 15:41\n",
      "773111  user_99ag1aCc  LWgass7yhgoi2uIk  2019-01-29 15:41\n",
      "773112  user_99ag1aCc  nUeW3T5zEakcRMUw  2019-01-29 15:48\n"
     ]
    }
   ],
   "source": [
    "print(df_listening_history[df_listening_history[\"user\"] == 'user_99ag1aCc'].head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
