{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check number of parameters and relevant info for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 models in src/models/\n",
      "==========================================================================================\n",
      "âœ“ BM3                  |  33,570,688 params (33.57M)\n",
      "âœ“ BPR                  |   1,695,680 params ( 1.70M)\n",
      "âŠ˜ DAMRS                | Skipped: Requires preprocessed graph files (item_graph_dict_2.npy)\n",
      "âœ“ BM3                  |  33,570,688 params (33.57M)\n",
      "âœ“ BPR                  |   1,695,680 params ( 1.70M)\n",
      "âŠ˜ DAMRS                | Skipped: Requires preprocessed graph files (item_graph_dict_2.npy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\dragon.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mm_adj = torch.load(mm_adj_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ DRAGON               |  37,305,214 params (37.31M)\n",
      "âœ“ DUALGNN              |   5,438,462 params ( 5.44M)\n",
      "âœ“ DUALGNN              |   5,438,462 params ( 5.44M)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\freedom.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.mm_adj = torch.load(mm_adj_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FREEDOM              |  33,566,528 params (33.57M)\n",
      "âœ“ GRCN                 |   4,524,478 params ( 4.52M)\n",
      "âœ“ GRCN                 |   4,524,478 params ( 4.52M)\n",
      "âœ“ ITEMKNNCBF           |           2 params ( 0.00M)\n",
      "âœ“ ITEMKNNCBF           |           2 params ( 0.00M)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\lattice.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image_adj = torch.load(image_adj_file)\n",
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\lattice.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_adj = torch.load(text_adj_file)\n",
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\lattice.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_adj = torch.load(text_adj_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LATTICE              |  33,566,530 params (33.57M)\n",
      "âŠ˜ LAYERGCN             | Skipped: Imports from models.common (circular import)\n",
      "âœ“ LGMREC               |  33,584,320 params (33.58M)\n",
      "âœ“ LGMREC               |  33,584,320 params (33.58M)\n",
      "âœ“ LIGHTGCN             |   1,695,680 params ( 1.70M)\n",
      "âœ“ LIGHTGCN             |   1,695,680 params ( 1.70M)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\mgcn.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image_adj = torch.load(image_adj_file)\n",
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\mgcn.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_adj = torch.load(text_adj_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ MGCN                 |  33,587,392 params (33.59M)\n",
      "âœ“ MMGCN                |  15,558,720 params (15.56M)\n",
      "âœ“ MMGCN                |  15,558,720 params (15.56M)\n",
      "âœ“ MVGAE                |     756,352 params ( 0.76M)\n",
      "âŠ˜ PGL                  | Skipped: Requires sparsesvd package\n",
      "âœ“ MVGAE                |     756,352 params ( 0.76M)\n",
      "âŠ˜ PGL                  | Skipped: Requires sparsesvd package\n",
      "âœ“ SELFCFED_LGN         |   1,699,840 params ( 1.70M)\n",
      "âœ“ SELFCFED_LGN         |   1,699,840 params ( 1.70M)\n",
      "use the pre adjcency matrix\n",
      "âœ“ SLMREC               |   2,028,032 params ( 2.03M)\n",
      "use the pre adjcency matrix\n",
      "âœ“ SLMREC               |   2,028,032 params ( 2.03M)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\smore.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image_adj = torch.load(image_adj_file)\n",
      "c:\\Users\\guanj\\Dev\\MMRec\\src\\models\\smore.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_adj = torch.load(text_adj_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SMORE                |  33,608,198 params (33.61M)\n",
      "âœ“ VBPR                 |   3,226,944 params ( 3.23M)\n",
      "==========================================================================================\n",
      "\n",
      "Successfully analyzed: 17 / 20 models\n",
      "Skipped (known issues): 3\n",
      "Failed (unexpected): 0\n",
      "\n",
      "====================================================================================================\n",
      "MODEL COMPARISON (Sorted by parameter count - Lower = Typically Faster)\n",
      "====================================================================================================\n",
      " Rank Model        Params (M)    Trainable    Frozen  Multimodal  GCN  Complexity\n",
      "    1 ITEMKNNCBF         0.00           2        0           âœ“    âœ—      Medium\n",
      "    2 MVGAE              0.76     756,352        0           âœ“    âœ—      Medium\n",
      "    3 BPR                1.70   1,695,680        0           âœ“    âœ—      Medium\n",
      "    4 LIGHTGCN           1.70   1,695,680        0           âœ“    âœ“        High\n",
      "    5 SELFCFED_LGN       1.70   1,699,840        0           âœ“    âœ—      Medium\n",
      "    6 SLMREC             2.03   2,028,032        0           âœ“    âœ—      Medium\n",
      "    7 VBPR               3.23   3,226,944        0           âœ“    âœ—      Medium\n",
      "    8 GRCN               4.52   4,524,478        0           âœ“    âœ—      Medium\n",
      "    9 DUALGNN            5.44   5,438,462        0           âœ“    âœ“        High\n",
      "   10 MMGCN             15.56  15,558,720        0           âœ“    âœ“        High\n",
      "   11 FREEDOM           33.57  33,566,528        0           âœ“    âœ—      Medium\n",
      "   12 LATTICE           33.57  33,566,530        0           âœ“    âœ—      Medium\n",
      "   13 BM3               33.57  33,570,688        0           âœ“    âœ—      Medium\n",
      "   14 LGMREC            33.58   2,000,320 31,584,000           âœ“    âœ—      Medium\n",
      "   15 MGCN              33.59  33,587,392        0           âœ“    âœ“        High\n",
      "   16 SMORE             33.61  33,608,198        0           âœ“    âœ—      Medium\n",
      "   17 DRAGON            37.31  37,305,214        0           âœ“    âœ—      Medium\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š SUMMARY STATISTICS:\n",
      "   Total models analyzed: 17\n",
      "   Smallest model: ITEMKNNCBF (0.00M params)\n",
      "   Largest model:  DRAGON (37.31M params)\n",
      "   Average size:   16.20M params\n",
      "   Multimodal models: 17\n",
      "   GCN/GNN-based: 4\n",
      "\n",
      "âš¡ TRAINING SPEED RANKING:\n",
      "\n",
      "   ðŸŸ¡ MODERATE (GCN or multimodal):\n",
      "      â€¢ ITEMKNNCBF     0.00M params\n",
      "      â€¢ MVGAE          0.76M params\n",
      "      â€¢ BPR            1.70M params\n",
      "      â€¢ SELFCFED_LGN   1.70M params\n",
      "      â€¢ SLMREC         2.03M params\n",
      "      â€¢ VBPR           3.23M params\n",
      "      â€¢ GRCN           4.52M params\n",
      "      â€¢ FREEDOM       33.57M params\n",
      "      â€¢ LATTICE       33.57M params\n",
      "      â€¢ BM3           33.57M params\n",
      "      â€¢ LGMREC        33.58M params\n",
      "      â€¢ SMORE         33.61M params\n",
      "      â€¢ DRAGON        37.31M params\n",
      "\n",
      "   ðŸ”´ SLOWEST (GCN + multimodal):\n",
      "      â€¢ LIGHTGCN       1.70M params\n",
      "      â€¢ DUALGNN        5.44M params\n",
      "      â€¢ MMGCN         15.56M params\n",
      "      â€¢ MGCN          33.59M params\n",
      "\n",
      "ðŸŽ¯ RECOMMENDATIONS FOR MUSIC4ALL DATASET:\n",
      "\n",
      "   Fast iteration models (< 5M params):\n",
      "      â€¢ ITEMKNNCBF    0.00M params - Multimodal\n",
      "      â€¢ MVGAE         0.76M params - Multimodal\n",
      "      â€¢ BPR           1.70M params - Multimodal\n",
      "\n",
      "   Graph-based models (best performance/speed trade-off):\n",
      "      â€¢ LIGHTGCN      1.70M params\n",
      "      â€¢ DUALGNN       5.44M params\n",
      "      â€¢ MMGCN        15.56M params\n",
      "\n",
      "ðŸ’¡ TRAINING SPEED FACTORS:\n",
      "   1. Parameter count: Direct impact on computation time\n",
      "   2. Graph operations: GCN/GNN adds ~2-3x overhead\n",
      "   3. Multimodal fusion: Feature processing adds time\n",
      "   4. Batch size: Larger batches improve GPU efficiency\n",
      "\n",
      "âœ“ Results saved to: model_comparison.csv\n",
      "âœ“ VBPR                 |   3,226,944 params ( 3.23M)\n",
      "==========================================================================================\n",
      "\n",
      "Successfully analyzed: 17 / 20 models\n",
      "Skipped (known issues): 3\n",
      "Failed (unexpected): 0\n",
      "\n",
      "====================================================================================================\n",
      "MODEL COMPARISON (Sorted by parameter count - Lower = Typically Faster)\n",
      "====================================================================================================\n",
      " Rank Model        Params (M)    Trainable    Frozen  Multimodal  GCN  Complexity\n",
      "    1 ITEMKNNCBF         0.00           2        0           âœ“    âœ—      Medium\n",
      "    2 MVGAE              0.76     756,352        0           âœ“    âœ—      Medium\n",
      "    3 BPR                1.70   1,695,680        0           âœ“    âœ—      Medium\n",
      "    4 LIGHTGCN           1.70   1,695,680        0           âœ“    âœ“        High\n",
      "    5 SELFCFED_LGN       1.70   1,699,840        0           âœ“    âœ—      Medium\n",
      "    6 SLMREC             2.03   2,028,032        0           âœ“    âœ—      Medium\n",
      "    7 VBPR               3.23   3,226,944        0           âœ“    âœ—      Medium\n",
      "    8 GRCN               4.52   4,524,478        0           âœ“    âœ—      Medium\n",
      "    9 DUALGNN            5.44   5,438,462        0           âœ“    âœ“        High\n",
      "   10 MMGCN             15.56  15,558,720        0           âœ“    âœ“        High\n",
      "   11 FREEDOM           33.57  33,566,528        0           âœ“    âœ—      Medium\n",
      "   12 LATTICE           33.57  33,566,530        0           âœ“    âœ—      Medium\n",
      "   13 BM3               33.57  33,570,688        0           âœ“    âœ—      Medium\n",
      "   14 LGMREC            33.58   2,000,320 31,584,000           âœ“    âœ—      Medium\n",
      "   15 MGCN              33.59  33,587,392        0           âœ“    âœ“        High\n",
      "   16 SMORE             33.61  33,608,198        0           âœ“    âœ—      Medium\n",
      "   17 DRAGON            37.31  37,305,214        0           âœ“    âœ—      Medium\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š SUMMARY STATISTICS:\n",
      "   Total models analyzed: 17\n",
      "   Smallest model: ITEMKNNCBF (0.00M params)\n",
      "   Largest model:  DRAGON (37.31M params)\n",
      "   Average size:   16.20M params\n",
      "   Multimodal models: 17\n",
      "   GCN/GNN-based: 4\n",
      "\n",
      "âš¡ TRAINING SPEED RANKING:\n",
      "\n",
      "   ðŸŸ¡ MODERATE (GCN or multimodal):\n",
      "      â€¢ ITEMKNNCBF     0.00M params\n",
      "      â€¢ MVGAE          0.76M params\n",
      "      â€¢ BPR            1.70M params\n",
      "      â€¢ SELFCFED_LGN   1.70M params\n",
      "      â€¢ SLMREC         2.03M params\n",
      "      â€¢ VBPR           3.23M params\n",
      "      â€¢ GRCN           4.52M params\n",
      "      â€¢ FREEDOM       33.57M params\n",
      "      â€¢ LATTICE       33.57M params\n",
      "      â€¢ BM3           33.57M params\n",
      "      â€¢ LGMREC        33.58M params\n",
      "      â€¢ SMORE         33.61M params\n",
      "      â€¢ DRAGON        37.31M params\n",
      "\n",
      "   ðŸ”´ SLOWEST (GCN + multimodal):\n",
      "      â€¢ LIGHTGCN       1.70M params\n",
      "      â€¢ DUALGNN        5.44M params\n",
      "      â€¢ MMGCN         15.56M params\n",
      "      â€¢ MGCN          33.59M params\n",
      "\n",
      "ðŸŽ¯ RECOMMENDATIONS FOR MUSIC4ALL DATASET:\n",
      "\n",
      "   Fast iteration models (< 5M params):\n",
      "      â€¢ ITEMKNNCBF    0.00M params - Multimodal\n",
      "      â€¢ MVGAE         0.76M params - Multimodal\n",
      "      â€¢ BPR           1.70M params - Multimodal\n",
      "\n",
      "   Graph-based models (best performance/speed trade-off):\n",
      "      â€¢ LIGHTGCN      1.70M params\n",
      "      â€¢ DUALGNN       5.44M params\n",
      "      â€¢ MMGCN        15.56M params\n",
      "\n",
      "ðŸ’¡ TRAINING SPEED FACTORS:\n",
      "   1. Parameter count: Direct impact on computation time\n",
      "   2. Graph operations: GCN/GNN adds ~2-3x overhead\n",
      "   3. Multimodal fusion: Feature processing adds time\n",
      "   4. Batch size: Larger batches improve GPU efficiency\n",
      "\n",
      "âœ“ Results saved to: model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Load base configs\n",
    "with open('src/configs/overall.yaml', 'r') as f:\n",
    "    base_config = yaml.safe_load(f)\n",
    "\n",
    "with open('src/configs/dataset/baby.yaml', 'r') as f:\n",
    "    dataset_config = yaml.safe_load(f)\n",
    "\n",
    "config = {**base_config, **dataset_config}\n",
    "config['dataset'] = 'baby'\n",
    "config['data_path'] = 'data/'\n",
    "config['device'] = torch.device('cpu')\n",
    "\n",
    "# ============================================================================\n",
    "# MOCK DATASET AND DATALOADER\n",
    "# ============================================================================\n",
    "\n",
    "# Load actual baby dataset for inter_matrix\n",
    "data_path = 'data/baby'\n",
    "inter_df = pd.read_csv(f'{data_path}/baby.inter', sep='\\t')\n",
    "\n",
    "class MockDataset:\n",
    "    \"\"\"Mock dataset that provides interaction matrix and basic statistics\"\"\"\n",
    "    def __init__(self, inter_df):\n",
    "        self.user_num = int(inter_df['userID'].max()) + 1\n",
    "        self.item_num = int(inter_df['itemID'].max()) + 1\n",
    "        self.df = inter_df\n",
    "        \n",
    "    def get_user_num(self):\n",
    "        return self.user_num\n",
    "    \n",
    "    def get_item_num(self):\n",
    "        return self.item_num\n",
    "    \n",
    "    def inter_matrix(self, form='coo'):\n",
    "        \"\"\"Generate sparse interaction matrix\"\"\"\n",
    "        users = self.df['userID'].values\n",
    "        items = self.df['itemID'].values\n",
    "        data = np.ones(len(users))\n",
    "        \n",
    "        if form == 'csr':\n",
    "            return sp.csr_matrix((data, (users, items)), shape=(self.user_num, self.item_num))\n",
    "        else:  # Default to 'coo'\n",
    "            return sp.coo_matrix((data, (users, items)), shape=(self.user_num, self.item_num))\n",
    "\n",
    "class MockDataLoader:\n",
    "    \"\"\"Mock dataloader that wraps dataset and provides inter_matrix method\"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def inter_matrix(self, form='coo'):\n",
    "        \"\"\"Pass-through to dataset's inter_matrix method\"\"\"\n",
    "        return self.dataset.inter_matrix(form)\n",
    "\n",
    "mock_dataset = MockDataset(inter_df)\n",
    "mock_dataloader = MockDataLoader(mock_dataset)\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL CLASS NAME MAPPING\n",
    "# ============================================================================\n",
    "\n",
    "# Map filename to actual class name for models with non-standard naming\n",
    "CLASS_NAME_MAP = {\n",
    "    'dualgnn': 'DualGNN',\n",
    "    'itemknncbf': 'ItemKNNCBF',\n",
    "    'lgmrec': 'LGMRec',\n",
    "    'lightgcn': 'LightGCN',\n",
    "    'selfcfed_lgn': 'SELFCFED_LGN',\n",
    "    'slmrec': 'SLMRec',\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# DEFAULT PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Common parameters with sensible defaults\n",
    "DEFAULT_PARAMS = {\n",
    "    'lambda_coeff': 0.1,\n",
    "    'cf_model': 'mf',\n",
    "    'n_layers': 2,\n",
    "    'dropout': 0.1,\n",
    "    'reg_weight': 1e-4,\n",
    "    'cl_weight': 0.1,\n",
    "    'temperature': 0.2,\n",
    "    'ssl_tau': 0.5,\n",
    "    'ssl_reg': 0.1,\n",
    "    'hyper_num': 64,\n",
    "    'n_ui_layers': 2,\n",
    "    'n_mm_layers': 2,\n",
    "    'n_layers_feat': 1,\n",
    "    'knn_k': 10,\n",
    "    'mm_image_weight': 0.5,\n",
    "    'aggr_mode': 'mean',\n",
    "    'degree_ratio': 0.5,\n",
    "    'cl_loss': 0.01,\n",
    "    'dropout_rate': 0.1,\n",
    "    'image_knn_k': 10,\n",
    "    'text_knn_k': 10,\n",
    "    'feat_embed_dim': 64,\n",
    "}\n",
    "\n",
    "# Parameters that should remain as lists (don't take first element)\n",
    "LIST_PARAMS = {\n",
    "    'weight_size',\n",
    "    'mess_dropout',\n",
    "    'hyper_parameters',\n",
    "}\n",
    "\n",
    "# Models that require special handling\n",
    "MODELS_TO_SKIP = {\n",
    "    'layergcn': 'Imports from models.common (circular import)',\n",
    "    'pgl': 'Requires sparsesvd package',\n",
    "    'damrs': 'Requires preprocessed graph files (item_graph_dict_2.npy)',\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "models_dir = Path('src/models')\n",
    "model_files = [f.stem for f in models_dir.glob('*.py') \n",
    "               if f.stem not in ['__init__', '__pycache__']]\n",
    "\n",
    "print(f\"Found {len(model_files)} models in src/models/\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "model_info = []\n",
    "skipped_models = []\n",
    "\n",
    "for model_name in sorted(model_files):\n",
    "    # Skip known problematic models\n",
    "    if model_name in MODELS_TO_SKIP:\n",
    "        reason = MODELS_TO_SKIP[model_name]\n",
    "        print(f\"âŠ˜ {model_name.upper():20s} | Skipped: {reason}\")\n",
    "        skipped_models.append((model_name, reason))\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Import the model module\n",
    "        module = importlib.import_module(f'models.{model_name}')\n",
    "        \n",
    "        # Try to find the model class\n",
    "        # First check if we have a mapping\n",
    "        if model_name in CLASS_NAME_MAP:\n",
    "            class_name = CLASS_NAME_MAP[model_name]\n",
    "        else:\n",
    "            # Try standard naming conventions\n",
    "            possible_names = [\n",
    "                model_name.upper(),  # UPPERCASE\n",
    "                ''.join([word.capitalize() for word in model_name.split('_')]),  # CamelCase\n",
    "                model_name,  # lowercase\n",
    "            ]\n",
    "            class_name = None\n",
    "            for name in possible_names:\n",
    "                if hasattr(module, name):\n",
    "                    class_name = name\n",
    "                    break\n",
    "        \n",
    "        if class_name is None or not hasattr(module, class_name):\n",
    "            print(f\"âœ— {model_name.upper():20s} | Error: Could not find model class\")\n",
    "            continue\n",
    "        \n",
    "        model_class = getattr(module, class_name)\n",
    "        \n",
    "        # Build config for this model\n",
    "        test_config = config.copy()\n",
    "        \n",
    "        # Load model-specific config if exists\n",
    "        model_config_path = f'src/configs/model/{model_name}.yaml'\n",
    "        if os.path.exists(model_config_path):\n",
    "            with open(model_config_path, 'r') as f:\n",
    "                model_specific_config = yaml.safe_load(f)\n",
    "            test_config.update(model_specific_config)\n",
    "        \n",
    "        # Add model name\n",
    "        test_config['model'] = model_name\n",
    "        \n",
    "        # Add default parameters for any missing keys\n",
    "        for key, value in DEFAULT_PARAMS.items():\n",
    "            if key not in test_config:\n",
    "                test_config[key] = value\n",
    "        \n",
    "        # Handle list parameters (take first value for instantiation, except for LIST_PARAMS)\n",
    "        for key, value in test_config.items():\n",
    "            if isinstance(value, list) and len(value) > 0 and key not in LIST_PARAMS:\n",
    "                test_config[key] = value[0]\n",
    "        \n",
    "        # Instantiate model\n",
    "        model = model_class(test_config, mock_dataloader)\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        frozen_params = total_params - trainable_params\n",
    "        \n",
    "        # Analyze model characteristics\n",
    "        is_multimodal = (hasattr(model, 'v_feat') or hasattr(model, 't_feat') or \n",
    "                        'mm' in model_name.lower() or 'multimodal' in model_name.lower())\n",
    "        has_gcn = ('gcn' in model_name.lower() or 'gnn' in model_name.lower() or \n",
    "                  'graph' in model_name.lower() or model_name.lower() == 'lightgcn')\n",
    "        \n",
    "        # Determine complexity\n",
    "        if has_gcn and is_multimodal:\n",
    "            complexity = 'High'\n",
    "        elif has_gcn or is_multimodal:\n",
    "            complexity = 'Medium'\n",
    "        else:\n",
    "            complexity = 'Low'\n",
    "        \n",
    "        model_info.append({\n",
    "            'model': model_name.upper(),\n",
    "            'total_params': total_params,\n",
    "            'trainable_params': trainable_params,\n",
    "            'frozen_params': frozen_params,\n",
    "            'is_multimodal': 'âœ“' if is_multimodal else 'âœ—',\n",
    "            'has_gcn': 'âœ“' if has_gcn else 'âœ—',\n",
    "            'complexity': complexity\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ“ {model_name.upper():20s} | {total_params:11,} params ({total_params/1e6:5.2f}M)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        # Truncate long error messages\n",
    "        if len(error_msg) > 60:\n",
    "            error_msg = error_msg[:57] + \"...\"\n",
    "        print(f\"âœ— {model_name.upper():20s} | Error: {error_msg}\")\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nSuccessfully analyzed: {len(model_info)} / {len(model_files)} models\")\n",
    "print(f\"Skipped (known issues): {len(skipped_models)}\")\n",
    "print(f\"Failed (unexpected): {len(model_files) - len(model_info) - len(skipped_models)}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# RESULTS TABLE\n",
    "# ============================================================================\n",
    "\n",
    "if model_info:\n",
    "    df_models = pd.DataFrame(model_info)\n",
    "    df_models = df_models.sort_values('total_params')\n",
    "    df_models['params_M'] = df_models['total_params'] / 1e6\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"MODEL COMPARISON (Sorted by parameter count - Lower = Typically Faster)\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"{'Rank':>5} {'Model':<12} {'Params (M)':>10}  {'Trainable':>11}  \"\n",
    "          f\"{'Frozen':>8} {'Multimodal':>11} {'GCN':>4} {'Complexity':>11}\")\n",
    "    \n",
    "    for rank, (_, row) in enumerate(df_models.iterrows(), 1):\n",
    "        print(f\"{rank:>5} {row['model']:<12} {row['params_M']:>10.2f} \"\n",
    "              f\"{row['trainable_params']:>11,} {row['frozen_params']:>8,} \"\n",
    "              f\"{row['is_multimodal']:>11} {row['has_gcn']:>4} {row['complexity']:>11}\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nðŸ“Š SUMMARY STATISTICS:\")\n",
    "    print(f\"   Total models analyzed: {len(df_models)}\")\n",
    "    print(f\"   Smallest model: {df_models.iloc[0]['model']} ({df_models.iloc[0]['params_M']:.2f}M params)\")\n",
    "    print(f\"   Largest model:  {df_models.iloc[-1]['model']} ({df_models.iloc[-1]['params_M']:.2f}M params)\")\n",
    "    print(f\"   Average size:   {df_models['params_M'].mean():.2f}M params\")\n",
    "    print(f\"   Multimodal models: {(df_models['is_multimodal'] == 'âœ“').sum()}\")\n",
    "    print(f\"   GCN/GNN-based: {(df_models['has_gcn'] == 'âœ“').sum()}\")\n",
    "    \n",
    "    # Speed ranking by complexity\n",
    "    print(f\"\\nâš¡ TRAINING SPEED RANKING:\")\n",
    "    \n",
    "    for complexity_level, emoji, desc in [\n",
    "        ('Low', 'ðŸŸ¢', 'FASTEST (Simple architectures)'),\n",
    "        ('Medium', 'ðŸŸ¡', 'MODERATE (GCN or multimodal)'),\n",
    "        ('High', 'ðŸ”´', 'SLOWEST (GCN + multimodal)')\n",
    "    ]:\n",
    "        subset = df_models[df_models['complexity'] == complexity_level]\n",
    "        if len(subset) > 0:\n",
    "            print(f\"\\n   {emoji} {desc}:\")\n",
    "            for _, row in subset.iterrows():\n",
    "                print(f\"      â€¢ {row['model']:<12} {row['params_M']:6.2f}M params\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nðŸŽ¯ RECOMMENDATIONS FOR MUSIC4ALL DATASET:\")\n",
    "    \n",
    "    # Get top 3 fastest\n",
    "    top3 = df_models.head(3)\n",
    "    print(f\"\\n   Fast iteration models (< 5M params):\")\n",
    "    for _, row in top3.iterrows():\n",
    "        if row['params_M'] < 5:\n",
    "            print(f\"      â€¢ {row['model']:<12} {row['params_M']:5.2f}M params - \"\n",
    "                  f\"{'Multimodal' if row['is_multimodal'] == 'âœ“' else 'CF-only'}\")\n",
    "    \n",
    "    # GCN models\n",
    "    gcn_models = df_models[df_models['has_gcn'] == 'âœ“'].head(3)\n",
    "    if len(gcn_models) > 0:\n",
    "        print(f\"\\n   Graph-based models (best performance/speed trade-off):\")\n",
    "        for _, row in gcn_models.iterrows():\n",
    "            print(f\"      â€¢ {row['model']:<12} {row['params_M']:5.2f}M params\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ TRAINING SPEED FACTORS:\")\n",
    "    print(f\"   1. Parameter count: Direct impact on computation time\")\n",
    "    print(f\"   2. Graph operations: GCN/GNN adds ~2-3x overhead\")\n",
    "    print(f\"   3. Multimodal fusion: Feature processing adds time\")\n",
    "    print(f\"   4. Batch size: Larger batches improve GPU efficiency\")\n",
    "    \n",
    "    # Export to CSV for reference\n",
    "    df_models[['model', 'params_M', 'complexity', 'is_multimodal', 'has_gcn']].to_csv(\n",
    "        'model_comparison.csv', index=False)\n",
    "    print(f\"\\nâœ“ Results saved to: model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect `data/baby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting dataset: baby ---\n",
      "Columns: ['userID', 'itemID', 'rating', 'timestamp', 'x_label']\n",
      "        userID  itemID  x_label\n",
      "160787   19444    7022        0\n",
      "160788   19444    6959        0\n",
      "160789   19444    7005        0\n",
      "160790   19444    7023        1\n",
      "160791   19444    6994        2\n",
      "#users:  19445, max:  19444\n",
      "#items:   7050, max:   7049\n",
      "#filtered interactions: 160792\n",
      "\n",
      "Shape of image_feat: (7050, 4096)\n",
      "Shape of text_feat : (7050, 384)\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def inspect_dataset(name, data_path, config_path):\n",
    "    with open(config_path, 'r', encoding='utf-8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # Load inter_file\n",
    "    inter_file_path = f'{data_path}/{config[\"inter_file_name\"]}'\n",
    "    image_file_path = f'{data_path}/{config[\"vision_feature_file\"]}'\n",
    "    text_file_path = f'{data_path}/{config[\"text_feature_file\"]}'\n",
    "\n",
    "    inter_df = pd.read_csv(inter_file_path, sep='\\t')\n",
    "    image_feat = np.load(image_file_path, allow_pickle=True)\n",
    "    text_feat = np.load(text_file_path, allow_pickle=True)\n",
    "    \n",
    "    # Inspect the dataframe\n",
    "    print(f'--- Inspecting dataset: {name} ---')\n",
    "    print(f'Columns: {inter_df.columns.tolist()}')\n",
    "    print(inter_df[['userID', 'itemID', 'x_label']].tail())\n",
    "    print(f'#users: {len(inter_df[\"userID\"].unique()):6}, max: {inter_df[\"userID\"].max():6}')\n",
    "    print(f'#items: {len(inter_df[\"itemID\"].unique()):6}, max: {inter_df[\"itemID\"].max():6}')\n",
    "    print(f'#filtered interactions: {len(inter_df)}\\n')\n",
    "\n",
    "    print(f'Shape of image_feat: {image_feat.shape}')\n",
    "    print(f'Shape of text_feat : {text_feat.shape}')\n",
    "    print('-----------------------------------\\n')\n",
    "\n",
    "dataset_name = 'baby'\n",
    "data_path = f'data/{dataset_name}'\n",
    "config_path = f'src/configs/dataset/{dataset_name}.yaml'\n",
    "inspect_dataset(dataset_name, data_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting dataset: Music4All ---\n",
      "Columns: ['userID', 'itemID', 'x_label']\n",
      "         userID  itemID  x_label\n",
      "5058229   14124   14553        2\n",
      "5058230   14124    7313        2\n",
      "5058231   14124   62596        2\n",
      "5058232   14124   63684        2\n",
      "5058233   14124   14553        2\n",
      "#users:  14125, max:  14124\n",
      "#items:  80735, max:  80734\n",
      "#filtered interactions: 5058234\n",
      "\n",
      "Shape of image_feat: (80735, 1024)\n",
      "Shape of text_feat : (80735, 384)\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Music4All'\n",
    "# Now using junction - simpler path!\n",
    "data_path = f'data/{dataset_name}'  # Junction points to Dragon-for-Music/data/Music4All\n",
    "config_path = f'src/configs/dataset/{dataset_name}.yaml'\n",
    "inspect_dataset(dataset_name, data_path, config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content below was copied from `Dragon-for-Music`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All features - Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         userID  itemID  x_label\n",
      "5058229   14126   19690        2\n",
      "5058230   14126    9878        2\n",
      "5058231   14126   84677        2\n",
      "5058232   14126   86170        2\n",
      "5058233   14126   19690        2\n",
      "#users: 14125, max: 14126\n",
      "#items: 80735, max: 109268\n",
      "#filtered interactions: 5058234\n",
      "Shape of text_feature : (109269, 384)\n",
      "Shape of audio_feature: (109269, 1024)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "data_path = 'data/Music4All'\n",
    "config_path = f'configs/dataset/Music4All.yaml'\n",
    "\n",
    "with open(config_path, 'r', encoding='utf-8') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Load interaction file and features\n",
    "inter_file_path = os.path.join(data_path, config['inter_file_name'])\n",
    "text_feature_path = os.path.join(data_path, config['text_feature_file'])            # text_feat.npy -> clean_\n",
    "audio_feature_path = os.path.join(data_path, config['vision_feature_file'])         # audio_feat_mert.npy -> clean_\n",
    "\n",
    "inter_df = pd.read_csv(inter_file_path, sep='\\t')\n",
    "text_feature = np.load(text_feature_path)\n",
    "audio_feature = np.load(audio_feature_path)\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(inter_df[['userID', 'itemID', 'x_label']].tail())\n",
    "print(f'#users: {inter_df[\"userID\"].nunique()}, max: {inter_df[\"userID\"].max()}')\n",
    "print(f'#items: {inter_df[\"itemID\"].nunique()}, max: {inter_df[\"itemID\"].max()}')\n",
    "print(f'#filtered interactions: {len(inter_df)}')\n",
    "\n",
    "print(f'Shape of text_feature : {text_feature.shape}')\n",
    "print(f'Shape of audio_feature: {audio_feature.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only items with interactions\n",
    "inter_df['itemID'], unique_item_list = pd.factorize(inter_df['itemID'], sort=True)\n",
    "unique_item_list = unique_item_list.tolist()\n",
    "\n",
    "clean_text_feature = text_feature[unique_item_list]\n",
    "clean_audio_feature = audio_feature[unique_item_list]\n",
    "\n",
    "np.save(f\"{data_path}/clean_text_feat.npy\", clean_text_feature)\n",
    "np.save(f\"{data_path}/clean_audio_feat.npy\", clean_audio_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure #users = max+1 (no skipping ids)\n",
    "inter_df['userID'], uniques = pd.factorize(inter_df['userID'], sort=True)\n",
    "print(inter_df.tail())\n",
    "print(f'#users: {inter_df[\"userID\"].nunique()}, max: {inter_df[\"userID\"].max()}')\n",
    "print(f'#items: {inter_df[\"itemID\"].nunique()}, max: {inter_df[\"itemID\"].max()}')\n",
    "print(f'#filtered interactions: {len(inter_df)}')\n",
    "\n",
    "inter_df.to_csv(f\"{data_path}/clean_filtered_interactions.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All: Audio features\n",
    "\n",
    "See `tools.m4a_data_prep.prep_audio_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All: Text features\n",
    "Activate the `sbert` conda env for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tools.m4a_data_prep import load_json_from_gcs, prep_text_features\n",
    "\n",
    "music4all_dir = 'gs://music4all/Music4All/'\n",
    "attr_path = os.path.join(music4all_dir, 'processed/attributes.json')\n",
    "val_path = os.path.join(music4all_dir, 'processed/attribute_values.json')\n",
    "\n",
    "attributes = load_json_from_gcs(attr_path)\n",
    "val = load_json_from_gcs(val_path)\n",
    "\n",
    "# text_feat = prep_text_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val=dict_keys(['artist', 'album_name', 'lang', 'release', 'key', 'mode', 'genre', 'tag'])\n",
      "Genres: count=  853; ['8-bit', 'a cappella', 'abstract', 'abstract hip hop', 'accordion', 'acid house', 'acid jazz', 'acid techno', 'acousmatic', 'acoustic blues', 'acoustic pop', 'adoracao', 'adventista', 'afrikaans', 'afro-funk', 'afrobeat', 'afropop', 'aggrotech', 'albanian pop', 'album rock', 'alternative country', 'alternative dance', 'alternative hip hop', 'alternative metal', 'alternative metalcore', 'alternative pop', 'alternative pop rock', 'alternative rock', 'ambient', 'ambient folk', 'ambient industrial', 'ambient techno', 'anadolu rock', 'anarcho-punk', 'anime', 'anthem', 'anti-folk', 'arabesk', 'armenian folk', 'armenian pop', 'art pop', 'art rock', 'asmr', 'atmosphere', 'atmospheric black metal', 'atmospheric doom', 'atmospheric sludge', 'australian rock', 'austropop', 'avant-garde']\n",
      "Tags  : count=19541; [' ', ' ambient', ' blues rock', ' classic rock', ' dance', ' dark ambient', ' deathcore', ' electronic', ' electronica', ' female vocalist', ' female vocalists', ' hip hop', ' house', ' male vocalists', ' oldies', ' piano', ' pop', ' pop rock', ' post-punk', ' post-rock', ' progressive metal', ' rock', ' rock and roll', ' synth pop', '#alternative', '#cagetheelephant', '#dayumintro', '#dope', '#newpshyhedelic', '#rockalternativo', '#yaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaas', '&lt;&gt;&lt;', '&lt;3', '&lt;33', \"'90s\", '+30mg', '-', '- - rainy day - -', '- - woods - -', '---21fh', '---28fh', '--1', '--4', '--5', '-10', '-15t', '-2', '-25t', '-3', '-30t']\n"
     ]
    }
   ],
   "source": [
    "print(f'val={val.keys()}')\n",
    "print(f'Genres: count={len(val[\"genre\"]):5}; {val[\"genre\"][:50]}')\n",
    "print(f'Tags  : count={len(val[\"tag\"]):5}; {val[\"tag\"][:50]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'song_id': '2Z3mv11Pg2Xdj3Fp', 'artist': 14998, 'album_name': 12017, 'lang': 11, 'release': 85, 'key': 7, 'mode': 1, 'genre': [338, 480, 337, 684], 'tag': [7029, 10381, 370, 7028, 7024, 14907]}\n"
     ]
    }
   ],
   "source": [
    "print(attributes['items'][4589])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ty Segall\n",
      "Freedom's Goblin\n",
      "2018\n",
      "garage rock\n",
      "lo-fi\n",
      "garage punk\n",
      "rock\n",
      "garage rock\n",
      "lo-fi\n",
      "2018\n",
      "garage punk\n",
      "garage\n",
      "rock\n"
     ]
    }
   ],
   "source": [
    "print(val['artist'][14998])\n",
    "print(val['album_name'][12017])\n",
    "print(val['release'][85])\n",
    "for i in [338, 480, 337, 684]:\n",
    "    print(val['genre'][i])\n",
    "for i in [7029, 10381, 370, 7028, 7024, 14907]:\n",
    "    print(val['tag'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All: Interaction data\n",
    "\n",
    "**`interaction.json`**\n",
    "```\n",
    "{\n",
    "  0: [12233, 23344, ...],\n",
    "  1: [],\n",
    "  ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userID  itemID  x_label\n",
      "5058229  14126   19690        2\n",
      "5058230  14126    9878        2\n",
      "5058231  14126   84677        2\n",
      "5058232  14126   86170        2\n",
      "5058233  14126   19690        2\n",
      "#users: 14125\n",
      "#items: 80735\n",
      "#filtered interactions: 5058234\n",
      "        userID  itemID  x_label\n",
      "5058229  14126   19690        2\n",
      "5058230  14126    9878        2\n",
      "5058231  14126   84677        2\n",
      "5058232  14126   86170        2\n",
      "5058233  14126   19690        2\n",
      "#users: 14125\n",
      "#items: 80735\n",
      "#filtered interactions: 5058234\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tools.m4a_data_prep import prep_interaction_data\n",
    "\n",
    "music4all_dir = 'gs://music4all/Music4All/'\n",
    "inter_path = os.path.join(music4all_dir, 'processed/interactions.json')\n",
    "attr_path = os.path.join(music4all_dir, 'processed/attributes.json')\n",
    "\n",
    "df = prep_interaction_data(inter_path, attr_path)\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(df.tail())\n",
    "print(f'#users: {len(df[\"userID\"].unique())}')\n",
    "print(f'#items: {len(df[\"itemID\"].unique())}')\n",
    "print(f'#filtered interactions: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if `interactions.json` preserves order from `listening_history.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            user              song         timestamp\n",
      "0  user_007XIjOr  DaTQ53TUmfP93FSr  2019-02-20 12:28\n",
      "1  user_007XIjOr  dGeyvi5WCOjDU7da  2019-02-20 12:35\n",
      "2  user_007XIjOr  qUm54NYOjeFhmKYx  2019-02-20 12:48\n",
      "3  user_007XIjOr  FtnuMT1DlevSR2n5  2019-02-20 12:52\n",
      "4  user_007XIjOr  LHETTZcSZLeaVOGh  2019-02-20 13:09\n"
     ]
    }
   ],
   "source": [
    "from gcs_utils import read_tsv_from_gcs\n",
    "\n",
    "hist_path = os.path.join(music4all_dir, 'listening_history.csv')\n",
    "df_listening_history = read_tsv_from_gcs(hist_path)\n",
    "\n",
    "print(df_listening_history.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking order preservation for 20 random users...\n",
      "\n",
      "User user_z4gXXNYv (encoded 13924): MISMATCH\n",
      "  First mismatch at index 203:\n",
      "    CSV context : [36963, 33688, 45464, 60178, 18463, 43264, 18463, 105599, 36364, 87603, 23975]\n",
      "    JSON context: [36963, 33688, 45464, 60178, 18463, 18463, 43264, 105599, 36364, 87603, 23975]\n",
      "  CSV length=386, JSON length=386\n",
      "\n",
      "User user_evGC0u2F (encoded 9315): MISMATCH\n",
      "  First mismatch at index 94:\n",
      "    CSV context : [4478, 14231, 47004, 29618, 35792, 5440, 53766, 79581, 102157, 6173, 102157]\n",
      "    JSON context: [4478, 14231, 47004, 29618, 35792, 53766, 5440, 79581, 102157, 6173, 102157]\n",
      "  CSV length=325, JSON length=325\n",
      "\n",
      "User user_Go9F9fEh (encoded 3945): MISMATCH\n",
      "  First mismatch at index 80:\n",
      "    CSV context : [104867, 24814, 80232, 56284, 47671, 5516, 74695, 56284, 1920, 52264, 104867]\n",
      "    JSON context: [104867, 24814, 80232, 56284, 47671, 74695, 5516, 56284, 1920, 52264, 104867]\n",
      "  CSV length=356, JSON length=356\n",
      "\n",
      "User user_amW83YPG (encoded 8396): OK\n",
      "User user_UmyMyUZG (encoded 7053): MISMATCH\n",
      "  First mismatch at index 43:\n",
      "    CSV context : [36618, 93780, 79052, 79950, 79774, 79774, 84876, 27379, 26799, 107806, 29111]\n",
      "    JSON context: [36618, 93780, 79052, 79950, 79774, 84876, 79774, 27379, 26799, 107806, 29111]\n",
      "  CSV length=238, JSON length=238\n",
      "\n",
      "User user_Nzttg4pb (encoded 5552): MISMATCH\n",
      "  First mismatch at index 243:\n",
      "    CSV context : [14729, 14729, 6904, 15982, 15982, 14729, 11571, 11571, 15982, 104640, 104640]\n",
      "    JSON context: [14729, 14729, 6904, 15982, 15982, 11571, 11571, 14729, 15982, 104640, 104640]\n",
      "  CSV length=386, JSON length=386\n",
      "\n",
      "User user_jwplUdJx (encoded 10505): OK\n",
      "User user_Zwy5adJh (encoded 8231): MISMATCH\n",
      "  First mismatch at index 74:\n",
      "    CSV context : [107586, 59585, 67064, 46999, 34878, 15366, 80719, 9611, 16339, 22444, 68387]\n",
      "    JSON context: [107586, 59585, 67064, 46999, 34878, 80719, 15366, 9611, 16339, 22444, 68387]\n",
      "  CSV length=310, JSON length=310\n",
      "\n",
      "User user_ztWGGYqQ (encoded 14097): MISMATCH\n",
      "  First mismatch at index 65:\n",
      "    CSV context : [18768, 44895, 52314, 18768, 30646, 77694, 30646, 66512, 36052, 12750, 1992]\n",
      "    JSON context: [18768, 44895, 52314, 18768, 30646, 30646, 77694, 66512, 36052, 12750, 1992]\n",
      "  CSV length=307, JSON length=307\n",
      "\n",
      "User user_OcITazbb (encoded 5675): OK\n",
      "User user_GOAyb1zl (encoded 3841): MISMATCH\n",
      "  First mismatch at index 48:\n",
      "    CSV context : [70592, 71206, 106973, 86375, 924, 87939, 107080, 71206, 89429, 93578, 27902]\n",
      "    JSON context: [70592, 71206, 106973, 86375, 924, 107080, 87939, 71206, 89429, 93578, 27902]\n",
      "  CSV length=377, JSON length=377\n",
      "\n",
      "User user_F8i6YbND (encoded 3534): MISMATCH\n",
      "  First mismatch at index 15:\n",
      "    CSV context : [32246, 43072, 78733, 60757, 73502, 25917, 78733, 43072, 78733, 32246, 106934]\n",
      "    JSON context: [32246, 43072, 78733, 60757, 73502, 43072, 78733, 25917, 78733, 32246, 106934]\n",
      "  CSV length=286, JSON length=286\n",
      "\n",
      "User user_4iW03QJr (encoded 1133): MISMATCH\n",
      "  First mismatch at index 118:\n",
      "    CSV context : [36421, 79814, 45965, 9855, 101756, 104867, 101756, 52314, 58817, 95248, 22011]\n",
      "    JSON context: [36421, 79814, 45965, 9855, 101756, 101756, 104867, 52314, 58817, 95248, 22011]\n",
      "  CSV length=405, JSON length=405\n",
      "\n",
      "User user_jgjQGyUN (encoded 10445): MISMATCH\n",
      "  First mismatch at index 133:\n",
      "    CSV context : [45984, 7606, 70135, 70135, 29945, 61409, 54338, 27296, 70135, 13055, 70640]\n",
      "    JSON context: [45984, 7606, 70135, 70135, 29945, 54338, 61409, 27296, 70135, 13055, 70640]\n",
      "  CSV length=352, JSON length=352\n",
      "\n",
      "User user_CMIS6jVV (encoded 2862): MISMATCH\n",
      "  First mismatch at index 242:\n",
      "    CSV context : [15982, 6904, 11571, 6362, 47101, 47101, 46760, 16774, 107255, 61250, 75827]\n",
      "    JSON context: [15982, 6904, 11571, 6362, 47101, 46760, 47101, 16774, 107255, 61250, 75827]\n",
      "  CSV length=397, JSON length=397\n",
      "\n",
      "User user_OkojHRw7 (encoded 5710): MISMATCH\n",
      "  First mismatch at index 84:\n",
      "    CSV context : [4014, 40578, 71396, 6047, 7772, 65586, 22728, 37373, 17277, 9950, 98488]\n",
      "    JSON context: [4014, 40578, 71396, 6047, 7772, 22728, 65586, 37373, 17277, 9950, 98488]\n",
      "  CSV length=442, JSON length=442\n",
      "\n",
      "User user_jZb5w2Gi (encoded 10411): OK\n",
      "User user_99ag1aCc (encoded 2158): MISMATCH\n",
      "  First mismatch at index 57:\n",
      "    CSV context : [43793, 85901, 107051, 83374, 84105, 37894, 13443, 87159, 106632, 41372, 8689]\n",
      "    JSON context: [43793, 85901, 107051, 83374, 84105, 13443, 37894, 87159, 106632, 41372, 8689]\n",
      "  CSV length=466, JSON length=466\n",
      "\n",
      "User user_3pVh5ryK (encoded 908): OK\n",
      "User user_iBJHb2Lj (encoded 10080): MISMATCH\n",
      "  First mismatch at index 375:\n",
      "    CSV context : [14889, 14889, 106772, 82106, 40610, 101174, 40610, 101174, 49051, 57133, 80079]\n",
      "    JSON context: [14889, 14889, 106772, 82106, 40610, 40610, 101174, 101174, 49051, 57133, 80079]\n",
      "  CSV length=394, JSON length=394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from tools.m4a_data_prep import load_json_from_gcs\n",
    "\n",
    "inter_path = 'gs://music4all/Music4All/processed/interactions.json'\n",
    "interactions = load_json_from_gcs(inter_path)\n",
    "\n",
    "def first_mismatch_with_context(list1, list2, window=10):\n",
    "    \"\"\"Return index, values, and context slices around the first mismatch.\"\"\"\n",
    "    for i, (a, b) in enumerate(zip(list1, list2)):\n",
    "        if a != b:\n",
    "            half = window // 2\n",
    "            start = max(0, i - half)\n",
    "            end = i + half + 1\n",
    "            return i, list1[start:end], list2[start:end]\n",
    "    if len(list1) != len(list2):\n",
    "        i = min(len(list1), len(list2))\n",
    "        half = window // 2\n",
    "        start = max(0, i - half)\n",
    "        end = i + half + 1\n",
    "        return i, list1[start:end], list2[start:end]\n",
    "    return None\n",
    "\n",
    "df = df_listening_history.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "# df = df_listening_history\n",
    "\n",
    "# Build lookup dicts for encoding\n",
    "user_to_idx = {u[\"user_id\"]: idx for idx, u in enumerate(attributes[\"users\"])}\n",
    "item_to_idx = {i[\"song_id\"]: idx for idx, i in enumerate(attributes[\"items\"])}\n",
    "\n",
    "# === Randomly sample 20 users ===\n",
    "all_users = df[\"user\"].unique().tolist()\n",
    "sample_users = random.sample(all_users, min(20, len(all_users)))\n",
    "\n",
    "print(\"Checking order preservation for 20 random users...\\n\")\n",
    "\n",
    "for user_id in sample_users:\n",
    "    user_idx = user_to_idx[user_id]\n",
    "\n",
    "    # from CSV (chronological order)\n",
    "    user_df = df[df[\"user\"] == user_id]\n",
    "    csv_songs = [item_to_idx[song] for song in user_df[\"song\"].tolist()]\n",
    "\n",
    "    # from JSON\n",
    "    json_songs = interactions.get(str(user_idx), [])\n",
    "\n",
    "    # compare\n",
    "    match = csv_songs == json_songs\n",
    "    print(f\"User {user_id} (encoded {user_idx}): \"\n",
    "        f\"{'OK' if match else 'MISMATCH'}\")\n",
    "\n",
    "    if not match:\n",
    "        mm = first_mismatch_with_context(csv_songs, json_songs, window=10)\n",
    "        if mm:\n",
    "            idx, csv_context, json_context = mm\n",
    "            print(f\"  First mismatch at index {idx}:\")\n",
    "            print(f\"    CSV context : {csv_context}\")\n",
    "            print(f\"    JSON context: {json_context}\")\n",
    "        print(f\"  CSV length={len(csv_songs)}, JSON length={len(json_songs)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user              song         timestamp\n",
      "773053  user_99ag1aCc  lrL4RAKX6f8Tz2h9  2019-01-23 13:59\n",
      "773054  user_99ag1aCc  gV9zey0BURekfwUz  2019-01-23 15:32\n",
      "773055  user_99ag1aCc  TjyPWv8mZY4HyiHG  2019-01-23 15:36\n",
      "773056  user_99ag1aCc  mqcCD4gTbcbp524p  2019-01-23 15:40\n",
      "773057  user_99ag1aCc  QKtqOEayujT7uiN8  2019-01-23 15:46\n",
      "773058  user_99ag1aCc  hiZOnY63Q67hWHMU  2019-01-23 18:27\n",
      "773059  user_99ag1aCc  SF0M6cQhMuaeirB5  2019-01-23 18:31\n",
      "773060  user_99ag1aCc  zDJheSwyuy4euMpX  2019-01-23 18:34\n",
      "773061  user_99ag1aCc  bgaW0PAE9g3ndI3H  2019-01-23 20:17\n",
      "773062  user_99ag1aCc  rfaYNZCE9bm2ERQI  2019-01-23 20:25\n",
      "773063  user_99ag1aCc  X90FM1k6kIL08QcO  2019-01-23 20:29\n",
      "773064  user_99ag1aCc  pzDReyjgfMr7mNTX  2019-01-23 20:33\n",
      "773065  user_99ag1aCc  82gbxU2ARroqVp1r  2019-01-24 14:42\n",
      "773066  user_99ag1aCc  BdpE84qRXtc9deX6  2019-01-24 14:47\n",
      "773067  user_99ag1aCc  rwM0ld0uwxjMK9Fh  2019-01-24 14:51\n",
      "773068  user_99ag1aCc  WHPR9OrFBOToYWXJ  2019-01-24 14:56\n",
      "773069  user_99ag1aCc  yqNY16s5yT0amiRZ  2019-01-24 15:01\n",
      "773070  user_99ag1aCc  kYYEw62LOX3v5RSg  2019-01-24 17:36\n",
      "773071  user_99ag1aCc  XT6awgFXZtMr2hbP  2019-01-24 17:41\n",
      "773072  user_99ag1aCc  lKHB4iC9HPTZLc7i  2019-01-24 17:45\n",
      "773073  user_99ag1aCc  R5gBzwNyzql9kzs3  2019-01-24 17:50\n",
      "773074  user_99ag1aCc  UamCmdVPgN6B4DMa  2019-01-24 17:54\n",
      "773075  user_99ag1aCc  n7xy1GPYNyMYgusl  2019-01-24 18:00\n",
      "773076  user_99ag1aCc  RPmWvNfWjSNfwcay  2019-01-25 14:35\n",
      "773077  user_99ag1aCc  yfm7RER1PWTqgjIp  2019-01-25 14:42\n",
      "773078  user_99ag1aCc  IiKMWlJ4N1MvBpHc  2019-01-25 14:45\n",
      "773079  user_99ag1aCc  rrsXRmaMir5yOrZf  2019-01-25 14:50\n",
      "773080  user_99ag1aCc  EmPJO7fTwQlTDjGG  2019-01-25 14:54\n",
      "773081  user_99ag1aCc  OvGwrp7cisRK2xw8  2019-01-25 15:01\n",
      "773082  user_99ag1aCc  CTB8ewr815LhFQHe  2019-01-25 15:04\n",
      "773083  user_99ag1aCc  kCJHgbVuvdOLX9fK  2019-01-25 15:07\n",
      "773084  user_99ag1aCc  KVNTAVj6n3JYvD62  2019-01-25 17:58\n",
      "773085  user_99ag1aCc  waWpImm1As7LxqrC  2019-01-25 18:02\n",
      "773086  user_99ag1aCc  CsYEhTtAWbA4m1A9  2019-01-25 18:07\n",
      "773087  user_99ag1aCc  5cPojQi6lGT6v6vY  2019-01-25 18:10\n",
      "773088  user_99ag1aCc  QHpSMv1WsSt3wr48  2019-01-25 18:15\n",
      "773089  user_99ag1aCc  yMBMsrb9prNZKdVI  2019-01-25 18:20\n",
      "773090  user_99ag1aCc  iUcyvVWtHhpX0kyd  2019-01-25 18:24\n",
      "773091  user_99ag1aCc  Y4fqXBKf1ohU1RVD  2019-01-25 18:28\n",
      "773092  user_99ag1aCc  BP9cUEbDxszul8jF  2019-01-25 18:33\n",
      "773093  user_99ag1aCc  pLKeEmwpCncgcbZG  2019-01-25 18:37\n",
      "773094  user_99ag1aCc  JduzBnlSWG90zUbw  2019-01-25 19:55\n",
      "773095  user_99ag1aCc  gV9zey0BURekfwUz  2019-01-25 19:55\n",
      "773096  user_99ag1aCc  JduzBnlSWG90zUbw  2019-01-25 19:55\n",
      "773097  user_99ag1aCc  TjyPWv8mZY4HyiHG  2019-01-25 20:00\n",
      "773098  user_99ag1aCc  mqcCD4gTbcbp524p  2019-01-25 20:04\n",
      "773099  user_99ag1aCc  QKtqOEayujT7uiN8  2019-01-25 20:10\n",
      "773100  user_99ag1aCc  XA9SwTx1F83oAjVI  2019-01-26 16:45\n",
      "773101  user_99ag1aCc  gV9zey0BURekfwUz  2019-01-27 15:23\n",
      "773102  user_99ag1aCc  TjyPWv8mZY4HyiHG  2019-01-27 15:27\n",
      "773103  user_99ag1aCc  YGhy20IyV1owojFa  2019-01-27 15:39\n",
      "773104  user_99ag1aCc  32m5suoC94ytD8Ed  2019-01-28 17:35\n",
      "773105  user_99ag1aCc  OoS59bfFx3nnkAJD  2019-01-28 17:38\n",
      "773106  user_99ag1aCc  mmLy5yZjUvxea3jy  2019-01-28 18:41\n",
      "773107  user_99ag1aCc  yj5hUpgxoy0S4F1m  2019-01-29 15:21\n",
      "773108  user_99ag1aCc  lJKIbZNzpS6IsNgh  2019-01-29 15:30\n",
      "773109  user_99ag1aCc  lj6ySCyFmRM53Kg1  2019-01-29 15:34\n",
      "773110  user_99ag1aCc  7dKoROBrFjEeDkwD  2019-01-29 15:41\n",
      "773111  user_99ag1aCc  LWgass7yhgoi2uIk  2019-01-29 15:41\n",
      "773112  user_99ag1aCc  nUeW3T5zEakcRMUw  2019-01-29 15:48\n"
     ]
    }
   ],
   "source": [
    "print(df_listening_history[df_listening_history[\"user\"] == 'user_99ag1aCc'].head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
